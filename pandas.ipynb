{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c18d99-af5e-4cd1-adfa-3eb5204e2d3d",
   "metadata": {},
   "source": [
    "# PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66f8fc-07b6-4f11-ae4c-b9389dc56f30",
   "metadata": {},
   "source": [
    "GETTING FAMILIAR WITH PANDAS :\n",
    "  -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92d461-b30d-45d1-b35f-60c76bb9dc3e",
   "metadata": {},
   "source": [
    "1. UNDERSTANDING DATAFRAMES AND SERIES :\n",
    "\n",
    "   By exploring Pandas' basic functionalities—starting with understanding DataFrames and Series, creating them from various data sources, and practicing common operations—you'll gain a solid foundation in using this powerful library. This knowledge will serve as the building blocks for more advanced data manipulation and analysis tasks in your data science journey.\n",
    "  - Install pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda89397-2359-4a97-8575-667de2e6b3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8cb14-855b-4902-a95b-b87e961c6b28",
   "metadata": {},
   "source": [
    "- Import pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ed00db-e641-42d0-9c0b-167fac360d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef24f8-52ee-4309-bf0b-34cccc013d90",
   "metadata": {},
   "source": [
    " - Series:\n",
    "\n",
    "A Pandas Series is a one-dimensional array-like object that can hold data of any type (integers, floats, strings, etc.). Each element in a Series has a label, also known as an index.\n",
    "Think of a Series as a column in a spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8010a0a4-c215-4b53-bbe1-6c6130233619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a Series\n",
    "data = [10, 20, 30, 40]\n",
    "s = pd.Series(data)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d032baab-35f1-485d-955d-3978897c07eb",
   "metadata": {},
   "source": [
    "- DataFrame:\n",
    "  \n",
    "A DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). It’s similar to a table in a relational database or an Excel spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23120f9c-796e-4534-8722-bb3e749adb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "dfe = pd.DataFrame(data)\n",
    "print(dfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246b9fa-1ead-4640-9285-783a24f5752f",
   "metadata": {},
   "source": [
    "2. CREATING DATAFRAMES AND SERIES FROM VARIOUS DATA SOURCES :\n",
    "   \n",
    "- From Lists :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0abfde1c-3732-483f-ba00-dd2e33118676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     5\n",
      "1    10\n",
      "2    15\n",
      "3    20\n",
      "dtype: int64\n",
      "   Column1  Column2\n",
      "0        1        4\n",
      "1        2        5\n",
      "2        3        6\n"
     ]
    }
   ],
   "source": [
    "# Series from a list\n",
    "data = [5, 10, 15, 20]\n",
    "s = pd.Series(data)\n",
    "print(s)\n",
    "# DataFrame from lists\n",
    "data = {'Column1': [1, 2, 3], 'Column2': [4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485e48f-57f6-4751-b6fe-ce533266e5ae",
   "metadata": {},
   "source": [
    "- From Dictionaries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43c6dc0f-107c-4653-b8ac-16774b9d6253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series : a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "dataframe:   Product  Price\n",
      "0       A  10.99\n",
      "1       B  15.49\n",
      "2       C   7.99\n"
     ]
    }
   ],
   "source": [
    "# Series from a dictionary\n",
    "data = {'a': 1, 'b': 2, 'c': 3}\n",
    "s = pd.Series(data)\n",
    "print(f\"series : {s}\")\n",
    "# DataFrame from a dictionary\n",
    "data = {\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    'Price': [10.99, 15.49, 7.99]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"dataframe: {df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96070aad-4710-4bc7-9c1a-cba15922e5e6",
   "metadata": {},
   "source": [
    "- From CSV Files :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78c5b377-8699-4c32-b265-2948aa34468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name Branch Section\n",
      "0   S1    CSD       A\n",
      "1   S2    CSE       C\n",
      "2   S3   MECH       B\n"
     ]
    }
   ],
   "source": [
    "# Reading a CSV file into a DataFrame\n",
    "df = pd.read_csv('students.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a20b5-8054-4320-9e40-3f5f20b28d88",
   "metadata": {},
   "source": [
    "3. COMMON OPERATIONS :\n",
    "   - Selecting Data :\n",
    "      1. Select a single column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ce980fb-66b9-4fbe-baed-2a0ec19727df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    S1\n",
      "1    S2\n",
      "2    S3\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['Name'])  # Returns a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814bc88d-4187-453f-a6e9-dff19284b3b1",
   "metadata": {},
   "source": [
    "         B. Select multiple columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4004115d-2ec6-403c-8c23-5b71f9e97d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name Branch\n",
      "0   S1    CSD\n",
      "1   S2    CSE\n",
      "2   S3   MECH\n"
     ]
    }
   ],
   "source": [
    "print(df[['Name', 'Branch']])  # Returns a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445229f1-f1a0-427f-b20f-2553810d9e65",
   "metadata": {},
   "source": [
    "  - FILTERING ROWS :\n",
    "      Filter rows based on a condition :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a4f844b-76ea-4998-8541-356dab351279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where Age is greater than 25\n",
    "filtered_df = dfe[dfe['Age'] > 25]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a58454-7117-4679-b5e1-b24e7945df77",
   "metadata": {},
   "source": [
    " - MODIFYING DATA :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0438223-32e2-4194-8eca-0474c64be667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   26     New York\n",
      "1      Bob   31  Los Angeles\n",
      "2  Charlie   36      Chicago\n"
     ]
    }
   ],
   "source": [
    "# Add a new column :\n",
    "dfe['Salary'] = [50000, 60000, 55000]\n",
    "# Modify existing data :\n",
    "dfe['Age'] = dfe['Age'] + 1  # Increase all ages by 1\n",
    "# Drop a column :\n",
    "dfe = dfe.drop('Salary', axis=1)  # Remove the 'Salary' column\n",
    "print(dfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad362a99-e1c0-47f7-bbf9-e53cbd4693fd",
   "metadata": {},
   "source": [
    "DATA HANDLING WITH PANDAS :\n",
    " -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb7eedf-b054-457c-a937-73222dc6c3ff",
   "metadata": {},
   "source": [
    "Data handling using Pandas, focuses on tasks such as reading data from files, handling missing data, and transforming data. The program also includes steps to clean and preprocess the data, including handling missing values, removing duplicates, and performing data type conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f43c0-0325-4c1f-a12d-1b5dfbdd5716",
   "metadata": {},
   "source": [
    "Reading Data from a CSV File :\n",
    " - The program reads data from a CSV file ('data.csv') into a Pandas DataFrame using 'pd.read_csv()'.\n",
    " - The 'print(df)' statement displays the original DataFrame.\n",
    "\n",
    "Handling Missing Data :\n",
    " - The program checks for missing values using 'df.isnull().sum()'.\n",
    " - Missing values in the Age column are filled with the mean age using 'fillna()'.\n",
    " - Missing values in the Salary column are filled with the median salary.\n",
    "\n",
    "Removing Duplicates :\n",
    " - The program removes duplicate rows from the DataFrame using 'drop_duplicates()'.\n",
    "\n",
    "Data Type Conversions :\n",
    " - The Age column is converted to integers using 'astype(int)'.\n",
    " - The Salary column is converted to floats using 'astype(float)'.\n",
    "\n",
    "Data Transformation :\n",
    " - A new column, Salary in Thousands, is created by dividing the Salary column by 1000.\n",
    "\n",
    "Saving the Cleaned Data :\n",
    " - The cleaned DataFrame is saved to a new CSV file ('cleaned_data.csv') using 'to_csv()'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "605e4fc3-f268-4178-85ab-67ea4d06d4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name   Age   Salary Department\n",
      "0    Alice  25.0  50000.0         HR\n",
      "1      Bob  30.0      NaN    Finance\n",
      "2  Charlie  35.0  70000.0         IT\n",
      "3    David   NaN  60000.0  Marketing\n",
      "4     Emma  28.0  55000.0         HR\n",
      "5      Bob  30.0  65000.0    Finance\n",
      "6    Frank  40.0  80000.0         IT\n",
      "\n",
      "Missing Values:\n",
      "Name          0\n",
      "Age           1\n",
      "Salary        1\n",
      "Department    0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame after handling missing values:\n",
      "      Name        Age   Salary Department\n",
      "0    Alice  25.000000  50000.0         HR\n",
      "1      Bob  30.000000  62500.0    Finance\n",
      "2  Charlie  35.000000  70000.0         IT\n",
      "3    David  31.333333  60000.0  Marketing\n",
      "4     Emma  28.000000  55000.0         HR\n",
      "5      Bob  30.000000  65000.0    Finance\n",
      "6    Frank  40.000000  80000.0         IT\n",
      "\n",
      "DataFrame after removing duplicates:\n",
      "      Name        Age   Salary Department\n",
      "0    Alice  25.000000  50000.0         HR\n",
      "1      Bob  30.000000  62500.0    Finance\n",
      "2  Charlie  35.000000  70000.0         IT\n",
      "3    David  31.333333  60000.0  Marketing\n",
      "4     Emma  28.000000  55000.0         HR\n",
      "5      Bob  30.000000  65000.0    Finance\n",
      "6    Frank  40.000000  80000.0         IT\n",
      "\n",
      "DataFrame after data type conversions:\n",
      "      Name  Age   Salary Department\n",
      "0    Alice   25  50000.0         HR\n",
      "1      Bob   30  62500.0    Finance\n",
      "2  Charlie   35  70000.0         IT\n",
      "3    David   31  60000.0  Marketing\n",
      "4     Emma   28  55000.0         HR\n",
      "5      Bob   30  65000.0    Finance\n",
      "6    Frank   40  80000.0         IT\n",
      "\n",
      "DataFrame after data transformation:\n",
      "      Name  Age   Salary Department  Salary in Thousands\n",
      "0    Alice   25  50000.0         HR                 50.0\n",
      "1      Bob   30  62500.0    Finance                 62.5\n",
      "2  Charlie   35  70000.0         IT                 70.0\n",
      "3    David   31  60000.0  Marketing                 60.0\n",
      "4     Emma   28  55000.0         HR                 55.0\n",
      "5      Bob   30  65000.0    Finance                 65.0\n",
      "6    Frank   40  80000.0         IT                 80.0\n",
      "\n",
      "Cleaned data saved to 'cleaned_info.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12156\\529893945.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  d['Age'].fillna(d['Age'].mean(), inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12156\\529893945.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  d['Salary'].fillna(d['Salary'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# step 1: Read the CSV file into a DataFrame\n",
    "d= pd.read_csv('info.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(d)\n",
    "\n",
    "# Step 2: Handling Missing Data\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(d.isnull().sum())\n",
    "\n",
    "# Fill missing values in the 'Age' column with the mean age\n",
    "d['Age'].fillna(d['Age'].mean(), inplace=True)\n",
    "\n",
    "# Fill missing values in the 'Salary' column with the median salary\n",
    "d['Salary'].fillna(d['Salary'].median(), inplace=True)\n",
    "\n",
    "print(\"\\nDataFrame after handling missing values:\")\n",
    "print(d)\n",
    "\n",
    "# Step 3: Removing Duplicates\n",
    "\n",
    "# Remove duplicate rows\n",
    "d.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(d)\n",
    "\n",
    "# Step 4: Data Type Conversions\n",
    "\n",
    "# Convert the 'Age' column to integers\n",
    "d['Age'] = d['Age'].astype(int)\n",
    "\n",
    "# Convert the 'Salary' column to floats\n",
    "d['Salary'] = d['Salary'].astype(float)\n",
    "\n",
    "print(\"\\nDataFrame after data type conversions:\")\n",
    "print(d)\n",
    "\n",
    "# Step 5: Data Transformation\n",
    "\n",
    "# Create a new column 'Salary in Thousands' by dividing the 'Salary' column by 1000\n",
    "d['Salary in Thousands'] = d['Salary'] / 1000\n",
    "\n",
    "print(\"\\nDataFrame after data transformation:\")\n",
    "print(d)\n",
    "\n",
    "# Step 6: Save the cleaned DataFrame to a new CSV file\n",
    "d.to_csv('cleaned_info.csv', index=False)\n",
    "print(\"\\nCleaned data saved to 'cleaned_info.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d52c351-74ef-4289-b74f-d270d36a8e5e",
   "metadata": {},
   "source": [
    "DATA ANALYSIS WITH PANDAS :\n",
    " -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9777c02-f835-4ee6-bc03-916e5bfe3e21",
   "metadata": {},
   "source": [
    "Data analysis with Pandas, focuses on generating summary statistics, grouping data, and applying aggregate functions. It also cover advanced data manipulation techniques like merging, joining, and concatenating DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bfefca-dca9-4d4e-b840-cb228da0dd5c",
   "metadata": {},
   "source": [
    "1. Creating a DataFrame :\n",
    "A DataFrame df is created using sample data containing employee names, departments, ages, and salaries.(which we have already learnt in above topics)\n",
    "2. Generating Summary Statistics :\n",
    "The describe() function generates summary statistics for numeric columns, such as count, mean, standard deviation, min, and max.\n",
    "\n",
    "3. Grouping Data and Applying Aggregate Functions :\n",
    " - The groupby() function groups the data by the 'Department' column and applies aggregate functions (e.g., mean, sum) to the 'Salary' column.\n",
    " - Multiple aggregate functions are applied to both 'Salary' and 'Age' columns.\n",
    "4. Advanced Data Manipulation:\n",
    " - Merging DataFrames: Combines df and df2 on the 'Name' column.\n",
    " - Joining DataFrames: Joins df and df2 using the 'Name' index.\n",
    " - Concatenating DataFrames: Stacks df and df3 vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c03907bb-d648-4608-89b1-04e7f165b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name Department  Age  Salary\n",
      "0    Alice         HR   25   50000\n",
      "1      Bob    Finance   30   60000\n",
      "2  Charlie         IT   35   70000\n",
      "3    David  Marketing   40   60000\n",
      "4     Emma         HR   28   55000\n",
      "5    Frank         IT   40   80000\n",
      "6    Grace    Finance   30   62000\n",
      "\n",
      "Summary Statistics:\n",
      "             Age        Salary\n",
      "count   7.000000      7.000000\n",
      "mean   32.571429  62428.571429\n",
      "std     5.883795   9897.089519\n",
      "min    25.000000  50000.000000\n",
      "25%    29.000000  57500.000000\n",
      "50%    30.000000  60000.000000\n",
      "75%    37.500000  66000.000000\n",
      "max    40.000000  80000.000000\n",
      "\n",
      "Grouped Data (Mean and Sum of Salary by Department):\n",
      "               mean     sum\n",
      "Department                 \n",
      "Finance     61000.0  122000\n",
      "HR          52500.0  105000\n",
      "IT          75000.0  150000\n",
      "Marketing   60000.0   60000\n",
      "\n",
      "Multiple Aggregates for 'Salary' and 'Age' by Department:\n",
      "             Salary                  Age        \n",
      "               mean     sum    max  mean min max\n",
      "Department                                      \n",
      "Finance     61000.0  122000  62000  30.0  30  30\n",
      "HR          52500.0  105000  55000  26.5  25  28\n",
      "IT          75000.0  150000  80000  37.5  35  40\n",
      "Marketing   60000.0   60000  60000  40.0  40  40\n",
      "\n",
      "Merged DataFrame (on 'Name'):\n",
      "      Name Department  Age  Salary  Bonus\n",
      "0    Alice         HR   25   50000   5000\n",
      "1      Bob    Finance   30   60000   6000\n",
      "2  Charlie         IT   35   70000   7000\n",
      "3    David  Marketing   40   60000   6000\n",
      "4     Emma         HR   28   55000   5500\n",
      "5    Grace    Finance   30   62000   6200\n",
      "\n",
      "Joined DataFrame (on 'Name'):\n",
      "      Name Department  Age  Salary   Bonus\n",
      "0    Alice         HR   25   50000  5000.0\n",
      "1      Bob    Finance   30   60000  6000.0\n",
      "2  Charlie         IT   35   70000  7000.0\n",
      "3    David  Marketing   40   60000  6000.0\n",
      "4     Emma         HR   28   55000  5500.0\n",
      "5    Frank         IT   40   80000     NaN\n",
      "6    Grace    Finance   30   62000  6200.0\n",
      "\n",
      "Concatenated DataFrame (df + df3):\n",
      "      Name Department  Age  Salary\n",
      "0    Alice         HR   25   50000\n",
      "1      Bob    Finance   30   60000\n",
      "2  Charlie         IT   35   70000\n",
      "3    David  Marketing   40   60000\n",
      "4     Emma         HR   28   55000\n",
      "5    Frank         IT   40   80000\n",
      "6    Grace    Finance   30   62000\n",
      "7    Isaac         IT   29   68000\n",
      "8    James    Finance   31   64000\n"
     ]
    }
   ],
   "source": [
    "# 1: Sample Data\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma', 'Frank', 'Grace'],\n",
    "    'Department': ['HR', 'Finance', 'IT', 'Marketing', 'HR', 'IT', 'Finance'],\n",
    "    'Age': [25, 30, 35, 40, 28, 40, 30],\n",
    "    'Salary': [50000, 60000, 70000, 60000, 55000, 80000, 62000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# 2: Generate Summary Statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 3: Grouping Data and Applying Aggregate Functions\n",
    "# Group by 'Department' and calculate the mean and sum of 'Salary'\n",
    "grouped = df.groupby('Department')['Salary'].agg(['mean', 'sum'])\n",
    "print(\"\\nGrouped Data (Mean and Sum of Salary by Department):\")\n",
    "print(grouped)\n",
    "\n",
    "# Group by 'Department' and calculate multiple aggregates for 'Salary' and 'Age'\n",
    "multi_grouped = df.groupby('Department').agg({\n",
    "    'Salary': ['mean', 'sum', 'max'],\n",
    "    'Age': ['mean', 'min', 'max']\n",
    "})\n",
    "print(\"\\nMultiple Aggregates for 'Salary' and 'Age' by Department:\")\n",
    "print(multi_grouped)\n",
    "\n",
    "# 4: Advanced Data Manipulation\n",
    "# Merging, Joining, and Concatenating DataFrames\n",
    "\n",
    "# Creating a second DataFrame for demonstration\n",
    "data2 = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma', 'Grace', 'Henry'],\n",
    "    'Bonus': [5000, 6000, 7000, 6000, 5500, 6200, 5800]\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Merging DataFrames on the 'Name' column\n",
    "merged_df = pd.merge(df, df2, on='Name')\n",
    "print(\"\\nMerged DataFrame (on 'Name'):\")\n",
    "print(merged_df)\n",
    "\n",
    "# Joining DataFrames\n",
    "# Assume df2 is an additional data about bonuses, using 'Name' as an index\n",
    "df2.set_index('Name', inplace=True)\n",
    "joined_df = df.join(df2, on='Name')\n",
    "print(\"\\nJoined DataFrame (on 'Name'):\")\n",
    "print(joined_df)\n",
    "\n",
    "# Concatenating DataFrames (stacking them vertically)\n",
    "data3 = {\n",
    "    'Name': ['Isaac', 'James'],\n",
    "    'Department': ['IT', 'Finance'],\n",
    "    'Age': [29, 31],\n",
    "    'Salary': [68000, 64000]\n",
    "}\n",
    "df3 = pd.DataFrame(data3)\n",
    "concatenated_df = pd.concat([df, df3], ignore_index=True)\n",
    "print(\"\\nConcatenated DataFrame (df + df3):\")\n",
    "print(concatenated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418638ff-8d5b-419a-80fd-0dbeb7f24658",
   "metadata": {},
   "source": [
    "APPLICATION IN DATA SCIENCE :\n",
    " -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8c31f-ee69-4281-ae0a-e52cd6e061d5",
   "metadata": {},
   "source": [
    "Pandas is used to perform a variety of essential data handling and analysis tasks, showcasing its ability to efficiently manipulate and analyze structured data. The following points highlight how the use of Pandas can significantly benefit a data science professional:\n",
    "\n",
    "- ADVANTAGES OF USING PANDAS :\n",
    " 1. Efficient Data Handling :\n",
    "  - DataFrames and Series : Pandas' primary data structures, DataFrames and Series, are optimized for handling large datasets efficiently. They provide powerful tools for data manipulation, such as indexing, slicing, filtering, and reshaping, which are not as straightforward or efficient with traditional Python data structures like lists and dictionaries.\n",
    " 2. Ease of Data Cleaning :\n",
    "  - Handling Missing Data : Pandas offers simple and intuitive methods for handling missing data, such as fillna() and dropna(). These functions make it easy to prepare data for analysis by filling in or removing incomplete data.\n",
    "  - Data Type Conversions : Converting data types is seamless with Pandas, ensuring that the data is in the correct format for analysis. Functions like astype() allow for easy conversions that are critical in data preprocessing.\n",
    " 3. Advanced Data Manipulation :\n",
    "  - Merging, Joining, and Concatenating : Pandas provides robust functions to merge, join, and concatenate datasets, enabling data scientists to combine multiple sources of data with ease. These operations are crucial when dealing with real-world datasets that often come from various sources and need to be integrated.\n",
    " 4. Comprehensive Data Analysis :\n",
    "  - Summary Statistics and Aggregation : Pandas simplifies the process of generating summary statistics and performing group-based aggregation, allowing data scientists to quickly gain insights into their data. Functions like groupby() and agg() facilitate complex analyses that would be cumbersome with basic Python structures.\n",
    "  - Exploratory Data Analysis (EDA) : Pandas is indispensable for EDA, providing tools to quickly explore datasets, understand distributions, and identify trends. The ability to easily slice and dice the data enables a data scientist to uncover patterns and relationships that inform further analysis.\n",
    "    \n",
    "- REAL-WORLD EXAMPLES OF PANDAS IN ACTION :\n",
    " 1. Data Cleaning :\n",
    "In the financial industry, datasets often come with missing values, duplicates, or incorrect formats. Pandas is essential for cleaning these datasets, ensuring that they are ready for accurate analysis and modeling.\n",
    " 2. Exploratory Data Analysis (EDA) :\n",
    "In marketing, EDA is used to understand customer behavior and segment markets. Pandas allows for quick aggregation and visualization of customer data, helping marketers identify key customer segments and tailor campaigns accordingly.\n",
    " 3. Merging Diverse Datasets :\n",
    "In scientific research, data often comes from multiple experiments or studies. Pandas enables researchers to merge these datasets efficiently, ensuring that all relevant information is combined into a cohesive dataset for analysis.\n",
    "\n",
    "- CONCLUSION :\n",
    "\n",
    "Pandas stands out as a vital tool for data science professionals due to its ability to handle complex data operations with ease and efficiency. Compared to traditional Python data structures, Pandas offers a more powerful and flexible approach to data manipulation and analysis. Whether it's cleaning data, performing exploratory data analysis, or merging datasets, Pandas empowers data scientists to work more effectively, leading to faster and more accurate insights. This efficiency is crucial in real-world applications where time and accuracy are paramount.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa517f85-461f-4590-8f3e-02d967a0b035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
